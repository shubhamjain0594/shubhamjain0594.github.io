<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Deep Learning on Dora&#39;s world</title>
    <link>https://shubhamjain0594.github.io/tags/deep-learning/</link>
    <description>Recent content in Deep Learning on Dora&#39;s world</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&amp;copy; 2016. All rights reserved.</copyright>
    <lastBuildDate>Fri, 26 May 2017 00:14:56 +0530</lastBuildDate>
    <atom:link href="https://shubhamjain0594.github.io/tags/deep-learning/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>A Glimpse of Re-Work Deep Learning Summit - Singapore, 2017</title>
      <link>https://shubhamjain0594.github.io/post/glimpses-of-rework-deep-learning-2017/</link>
      <pubDate>Fri, 26 May 2017 00:14:56 +0530</pubDate>
      
      <guid>https://shubhamjain0594.github.io/post/glimpses-of-rework-deep-learning-2017/</guid>
      <description>&lt;p&gt;Last week of April 2017, I was attending &lt;a href=&#34;https://re-work.co/events/deep-learning-summit-singapore-april-2017&#34;&gt;Re-work Deep Learning Summit&lt;/a&gt; in Singapore. I was representing Qure.ai and speaking about some of the work we have been doing in this field. The conference had speakers from &lt;a href=&#34;https://deepmind.com&#34;&gt;Google Deepmind&lt;/a&gt;, &lt;a href=&#34;http://research.baidu.com/silicon-valley-ai-lab/&#34;&gt;Baidu Silicon Valley AI Lab&lt;/a&gt;, &lt;a href=&#34;http://facebook.com&#34;&gt;Facebook&lt;/a&gt;; startups such as &lt;a href=&#34;http://www.kata.ai&#34;&gt;Kata.ai&lt;/a&gt;, &lt;a href=&#34;http://www.smartcow.ai&#34;&gt;SmartCow.ai&lt;/a&gt;; investor firms such as &lt;a href=&#34;https://www.zeroth.ai&#34;&gt;Zeroth.ai&lt;/a&gt;, etc. In this post, I will introduce to you about all the impressive ideas I learned about in the conference.&lt;/p&gt;

&lt;p&gt;In a talk demonstrating use-case of &lt;a href=&#34;https://intl.aliyun.com&#34;&gt;PAI - Platform for AI&lt;/a&gt; via AliMe, two ideas that caught me up where:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Lazy Multiplication for Communication Optimization in Cloud&lt;/li&gt;
&lt;li&gt;Beam Search Decoders for Seq2Seq models&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In another talk by &lt;a href=&#34;https://www.linkedin.com/in/crischenli/&#34;&gt;Li Chen&lt;/a&gt; on Datacenter-Scale Deep Learning, I learned that&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Tensorflow uses gRPC which is quite slow for tensor communication across the network. This &lt;a href=&#34;https://github.com/tensorflow/tensorflow/issues/6116&#34;&gt;issue&lt;/a&gt; highlights the problem&lt;/li&gt;
&lt;li&gt;This can be solved by augmenting tensorflow with &lt;a href=&#34;https://www.microsoft.com/en-us/research/wp-content/uploads/2016/11/rdma_sigcomm2016.pdf&#34;&gt;RDMA transport layer protocol over RoCE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This insight was useful to understand that open-sourced tensorflow might have a lot of suboptimal code pieces. Small changes like mentioned, can lead to speed up of more than 6x. Also, it might be the case that internally Google uses a different version of tensorflow than what is open sourced.&lt;/p&gt;

&lt;p&gt;One of the reassuring ideas I encountered is of unsupervised pre-training. Initializing the weights of the network using unsupervised learning. This for further emphasized by &lt;a href=&#34;https://www.linkedin.com/in/vikramanksingh&#34;&gt;Vikramank Singh&lt;/a&gt; from Facebook in his talk on NLP in Deep Learning. &lt;a href=&#34;http://www.socher.org/index.php/Main/SemanticCompositionalityThroughRecursiveMatrix-VectorSpaces&#34;&gt;Semantic Compositionality through recursive matrix-vector spaces&lt;/a&gt; mentioned by Vikramank was pretty impressive, as it goes beyond word vectors towards word matrices.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/yardstick17/&#34;&gt;Amit Kushwaha&lt;/a&gt;, Zomato explained about their work in assessment of image aesthetics using &lt;a href=&#34;https://arxiv.org/abs/1406.4729&#34;&gt;Spatial Pyramid Pooling&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/anuroopsriram/&#34;&gt;Anuroop Sriram&lt;/a&gt;, Baidu SVAIL gave some pretty interesting ideas on End-to-End Speech Recognition. Some interesting concepts introduced included&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;SortaGrad Layer&lt;/li&gt;
&lt;li&gt;CTC or Connectionist Temporal Classification Loss&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The details about it can be found in &lt;a href=&#34;https://arxiv.org/pdf/1512.02595.pdf&#34;&gt;this&lt;/a&gt; paper. Another idea he mentioned is of &lt;a href=&#34;https://arxiv.org/pdf/1607.05666.pdf&#34;&gt;per-channel energy normalization&lt;/a&gt; to improve robustness to loudness variation.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.ritchieng.com&#34;&gt;Ritchie Ng&lt;/a&gt; introduced us to the idea of Hyperparameter Optimization using LSTMs. It is a work his team is going to publish in coming months. It can help us get rid of scheduling LR, momentum, etc. without compromising on accuracy or speed of convergence.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/brian-cheung-79480779/&#34;&gt;Brian Cheung&lt;/a&gt;, Ph.D. student at UC Berkeley presented his work in relation to adversarial component analysis&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Adversarial Independent Component Analysis to improve training of autoencoders&lt;/li&gt;
&lt;li&gt;Domain adaptation as adversarial problem&lt;/li&gt;
&lt;li&gt;Overfitting as adversarial problem&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This work will be published soon. Another &lt;a href=&#34;https://arxiv.org/abs/1611.09430&#34;&gt;work&lt;/a&gt; Brian has published is an architecture for attention models which works very similar to fovea in our eyes for image sampling.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.linkedin.com/in/jeffreydf/&#34;&gt;Jeffrey De Fauw&lt;/a&gt;, Research Engineer at Deepmind gave us a peek into their work via &lt;a href=&#34;https://www.kaggle.com/c/diabetic-retinopathy-detection&#34;&gt;Diabetic Retinopathy challenge&lt;/a&gt; hosted on Kaggle in 2016. Few interesting things I noticed from his presentation regarding Deepmind and his project in particular:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;They spend a good time analyzing the data, cases where model fails and preprocessing. I believe this is the key take away - rather than trying newer models and fancier architectures, more time must be spent on data and error analytics.&lt;/li&gt;
&lt;li&gt;Oversampling is not same as loss weights&lt;/li&gt;
&lt;li&gt;One of the really cool findings of data analytics was, the camera used for taking photos of an eye can itself produce some artifacts. But these artifacts will be at the same position for both left and right eye. So training the net with an input as a six-channel image (3-channels per eye) will lead to better accuracy.&lt;/li&gt;
&lt;li&gt;Using &lt;a href=&#34;https://arxiv.org/abs/1608.04802&#34;&gt;non-decomposable objective&lt;/a&gt; functions for measuring loss&lt;/li&gt;
&lt;li&gt;Log-max ensembling rather than simply majority vote&lt;/li&gt;
&lt;li&gt;Using dropouts during test, inspiration from &lt;a href=&#34;http://biorxiv.org/content/early/2016/10/28/084210&#34;&gt;this&lt;/a&gt; paper&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&#34;https://papernot.fr&#34;&gt;Nicolas Papernot&lt;/a&gt;, Google Ph.D. Fellow in Security presented his work in Security and Privacy in Machine Learning. &lt;a href=&#34;http://www.cleverhans.io/about/&#34;&gt;Cleverhans&lt;/a&gt; is an open-source library for benchmarking the vulnerability of machine learning models to adversarial examples. Its created by &lt;a href=&#34;http://www.iangoodfellow.com&#34;&gt;Ian Goodfellow&lt;/a&gt;, Research Scientist at OpenAI and Nicolas.&lt;/p&gt;

&lt;p&gt;My talk was on how important is to build trust with doctors for deep learning models in medical imaging. And few approaches we are trying at &lt;a href=&#34;www.qure.ai&#34;&gt;Qure.ai&lt;/a&gt;, results we have obtained and the future directions. Another idea my friend &lt;a href=&#34;https://www.linkedin.com/in/yapjiaqing/&#34;&gt;Jia Qing Yap&lt;/a&gt;, Executive Lead and Deep Learning Engineer at OpenSourceSDC was of &lt;a href=&#34;https://arxiv.org/abs/1704.05776&#34;&gt;recurrent rolling convolutions&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It was a great experience, thanks to Re-work team for inviting me. You must checkout &lt;a href=&#34;https://re-work.co/events/deep-learning-summit-montreal-canada-track1-2017&#34;&gt;Re-Work DL Summit Montreal&lt;/a&gt;. The lineup is super awesome.&lt;/p&gt;

&lt;p&gt;For any comments, suggestions or appreciations tweet &lt;a href=&#34;https://twitter.com/shubhamjain0594&#34;&gt;@shubhamjain0594&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Tutorials in NIPS 2016</title>
      <link>https://shubhamjain0594.github.io/post/nips-2016/</link>
      <pubDate>Sat, 10 Dec 2016 19:10:29 +0530</pubDate>
      
      <guid>https://shubhamjain0594.github.io/post/nips-2016/</guid>
      <description>

&lt;p&gt;This is a collection of all material I was able to find for various tutorials of NIPS 2016 for people who were not able to attend it and are really excited to know whats going on and can&amp;rsquo;t wait for official videos and slides.&lt;/p&gt;

&lt;h3 id=&#34;crowdsourcing-beyond-label-generation-https-nips-cc-conferences-2016-schedule-showevent-6205&#34;&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule?showEvent=6205&#34;&gt;Crowdsourcing: Beyond Label Generation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.jennwv.com/projects/crowdtutorial.html&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;variational-inference-foundations-and-modern-methods-https-nips-cc-conferences-2016-schedule-showevent-6199&#34;&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule?showEvent=6199&#34;&gt;Variational Inference: Foundations and Modern Methods&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cs.columbia.edu/~blei/talks/2016_NIPS_VI_tutorial.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;deep-reinforcement-learning-through-policy-optimization-https-nips-cc-conferences-2016-schedule-showevent-6198&#34;&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule?showEvent=6198&#34;&gt;Deep Reinforcement Learning Through Policy Optimization&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://people.eecs.berkeley.edu/~pabbeel/nips-tutorial-policy-optimization-Schulman-Abbeel.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;nuts-and-bolts-of-building-applications-using-deep-learning-andrew-ng-https-nips-cc-conferences-2016-schedule-showevent-6203&#34;&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule?showEvent=6203&#34;&gt;Nuts and Bolts of Building Applications using Deep Learning - Andrew Ng&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://www.dropbox.com/s/dyjdq1prjbs8pmc/NIPS2016%20-%20Pages%202-6%20(1).pdf&#34;&gt;Slides&lt;/a&gt;
Video from talk by Andrew Ng on same talk but somewhere else is &lt;a href=&#34;https://www.youtube.com/watch?v=F1ka6a13S9I&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;theory-and-algorithms-for-forecasting-non-stationary-time-series-https-nips-cc-conferences-2016-schedule-showevent-6206&#34;&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule?showEvent=6206&#34;&gt;Theory and Algorithms for Forecasting Non-Stationary Time Series&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&#34;natural-language-processing-for-computational-social-science-https-nips-cc-conferences-2016-schedule-showevent-6201&#34;&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule?showEvent=6201&#34;&gt;Natural Language Processing for Computational Social Science&lt;/a&gt;&lt;/h3&gt;

&lt;h3 id=&#34;large-scale-optimization-beyond-stochastic-gradient-descent-and-convexity-https-nips-cc-conferences-2016-schedule-showevent-6200&#34;&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule?showEvent=6200&#34;&gt;Large-Scale Optimization: Beyond Stochastic Gradient Descent and Convexity&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://suvrit.de/papers/vr_nips16_bach.pdf&#34;&gt;Slides - I&lt;/a&gt;
&lt;a href=&#34;http://suvrit.de/papers/vr_nips16_sra.pdf&#34;&gt;Slides - II&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;generative-adversarial-networks-ian-goodfellow-https-nips-cc-conferences-2016-schedule-showevent-6202&#34;&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule?showEvent=6202&#34;&gt;Generative Adversarial Networks - Ian Goodfellow&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://www.iangoodfellow.com/slides/2016-12-04-NIPS.pdf&#34;&gt;Slides&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;ml-foundations-and-methods-for-precision-medicine-and-healthcare-https-nips-cc-conferences-2016-schedule-showevent-6204&#34;&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule?showEvent=6204&#34;&gt;ML Foundations and Methods for Precision Medicine and Healthcare&lt;/a&gt;&lt;/h3&gt;
</description>
    </item>
    
    <item>
      <title>Deep Learning and AI videos</title>
      <link>https://shubhamjain0594.github.io/post/deep-learning-ai-videos/</link>
      <pubDate>Wed, 23 Nov 2016 17:38:15 +0530</pubDate>
      
      <guid>https://shubhamjain0594.github.io/post/deep-learning-ai-videos/</guid>
      <description>

&lt;p&gt;I like to hear things in my background while I am working. Music seems pleasure but sometimes also a distraction. At such points I play some good random videos in background. These help me in gaining new knowledge but at the same time does not distract me from work. I have compiled a small list of such videos in deep learning that I have heard so far and loved them. Will go on adding more.&lt;/p&gt;

&lt;h3 id=&#34;plenary-panel-is-deep-learning-the-new-42-https-www-youtube-com-watch-v-furfdqtdavc&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=furfdqtdAvc&#34;&gt;Plenary Panel: Is Deep Learning the New 42?&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;This video is the best panel discussion in Deep learning I have come so far. The best points I loved about it were the discussion on &lt;a href=&#34;https://arxiv.org/abs/1606.08813&#34;&gt;reforms&lt;/a&gt; introduced in European Union on algorithmic decision making and right to explanation. Another thing is when they talk about how biological, psychological and other studies have influenced Computer Science. And apparently conv nets which are leading structures in deep learning and vision are inspired by the study in 1970s. So the study of brains, vision, psychology, etc. will be the major influencers of future technology. The panel also puts light into what should a PhD student starting in DL now must do and what not, some really hot research topics that needs attention.&lt;/p&gt;

&lt;h3 id=&#34;artificial-intelligence-and-the-future-demis-hassabis-rsa-replay-https-www-youtube-com-watch-v-i3leg6argm8&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=i3lEG6aRGm8&#34;&gt;Artificial Intelligence and the Future | Demis Hassabis | RSA Replay&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Demis Hassabis takes on stage to explain AI and more specifically Artificial General Intelligence. 2016 has been the year of Alpha-Go and Hassabis explains what it is, and intuition into why does it work. I loved the part where he explains the special moves played by Alpha-Go that were out of the box, and more amazingly the author also points out the move by Lee Sedol (the opponent) in 4th game that made him the winner. A good watch if you want to know more about AGI and what future will look like.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>The End of Deconvolutions</title>
      <link>https://shubhamjain0594.github.io/post/the-end-of-deconv/</link>
      <pubDate>Sun, 13 Nov 2016 17:28:22 +0530</pubDate>
      
      <guid>https://shubhamjain0594.github.io/post/the-end-of-deconv/</guid>
      <description>&lt;p&gt;Deconvolutions were introduced in 2014 in &lt;a href=&#34;https://arxiv.org/abs/1411.4038&#34;&gt;&amp;ldquo;Fully Convolutional Networks for Semantic Segmentation&amp;rdquo;&lt;/a&gt; and has been extensively used in Semantic Segmentation and Generative Adversarial Networks. But its saturated now and the problems involved with it including checkerboard effects play a huge role in the error it produces. &lt;a href=&#34;http://distill.pub/2016/deconv-checkerboard/&#34;&gt;This&lt;/a&gt; blog post goes down the journey of deconvolutions and problems associated with it. It also suggests some solutions and how it can be replaced by better alternatives such as &lt;a href=&#34;https://arxiv.org/abs/1609.05158&#34;&gt;subpixel-cnn&lt;/a&gt;. If you are doing segmentation or working with generative networks, its time to move away from deconv.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hugo Larochelle TEDx</title>
      <link>https://shubhamjain0594.github.io/post/hugo-larochelle-ted/</link>
      <pubDate>Sat, 12 Nov 2016 18:13:08 +0530</pubDate>
      
      <guid>https://shubhamjain0594.github.io/post/hugo-larochelle-ted/</guid>
      <description>&lt;p&gt;This TED talk takes you through the journey of Deep Learning in last ten years and its amazing to see how it has evolved from a time when neural nets were not trusted and there were just a few countable people working, to today when there are so many people that you can find 4 research groups working on a similar idea at the end of the day. Pretty insightful and interesting and in a way it shows how a new technology comes into play and we should keep looking for small kicks, they maybe the thing of the future.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.dmi.usherb.ca/~larocheh/index_en.html&#34;&gt;Hugo Larochelle&lt;/a&gt; is a Research Scientist at Twitter and an Assistant Professor at the Université de Sherbrooke (UdeS). Before 2011, he spent two years in the machine learning group at the University of Toronto, as a postdoctoral fellow under the supervision of Geoffrey Hinton. He obtained his Ph.D. at Université de Montréal, under the supervision of Yoshua Bengio. He is the recipient of two Google Faculty Awards. His professional involvement includes associate editor for the IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), member of the editorial board of the Journal of Artificial Intelligence Research (JAIR) and program chair for the International Conference on Learning Representations (ICLR) of 2015, 2016 and 2017.&lt;/p&gt;

&lt;p&gt;Source: &lt;a href=&#34;https://www.youtube.com/watch?v=dz_jeuWx3j0&#34;&gt;Youtube&lt;/a&gt;
Video Link: &lt;a href=&#34;https://www.youtube.com/watch?v=dz_jeuWx3j0&#34;&gt;https://www.youtube.com/watch?v=dz_jeuWx3j0&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cool NN and DL applications</title>
      <link>https://shubhamjain0594.github.io/post/cool-nn-dl-applications/</link>
      <pubDate>Sun, 18 Sep 2016 14:54:14 +0530</pubDate>
      
      <guid>https://shubhamjain0594.github.io/post/cool-nn-dl-applications/</guid>
      <description>

&lt;p&gt;Deep learning and Neural Networks have some really cool applications (ideas), and here are a few I have come across and are really tangential to mainstream applications.&lt;/p&gt;

&lt;h2 id=&#34;defeating-image-obfuscation-with-deep-learning-https-arxiv-org-pdf-1609-00408v2-pdf&#34;&gt;&lt;a href=&#34;https://arxiv.org/pdf/1609.00408v2.pdf&#34;&gt;Defeating Image Obfuscation with Deep Learning&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1609.00408v2.pdf&#34;&gt;This&lt;/a&gt; paper from Cornell and University of Texas at Austin uses DL to reconstruct the images which are pixelated, blurred or encrypted using privacy-preserving photo (P3) algorithm. These techniques are many times used to hide the identities in some sensitive videos and photos in various media. These techniques are as well used in cryptography and hence current DL methods will push cryptographes to discover methods to ensure privacy of media can be maintained.&lt;/p&gt;

&lt;h2 id=&#34;detecting-the-programming-language-of-source-code-snippets-using-machine-learning-and-neural-networks-http-danielheres-space-jekyll-update-2016-07-18-detecting-the-programming-language-of-source-code-snippets-using-machine-learning-and-neural-networks-html&#34;&gt;&lt;a href=&#34;(http://danielheres.space/jekyll/update/2016/07/18/detecting-the-programming-language-of-source-code-snippets-using-machine-learning-and-neural-networks.html)&#34;&gt;Detecting the Programming Language of Source Code Snippets using Machine Learning and Neural Networks&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;I came across &lt;a href=&#34;http://danielheres.space/jekyll/update/2016/07/18/detecting-the-programming-language-of-source-code-snippets-using-machine-learning-and-neural-networks.html&#34;&gt;this&lt;/a&gt; blog post while searching for something related to compilation. I found this idea very appreciative and that can be implemented by multiple code engines like &lt;a href=&#34;codechef.com&#34;&gt;codechef&lt;/a&gt;, &lt;a href=&#34;hackerrank.com&#34;&gt;hackerrank&lt;/a&gt;, etc. It is a well thought and built approach and does not even use deep neural nets for the purpose. They have also hosted a &lt;a href=&#34;http://petiteprogrammer.com/&#34;&gt;trial platform&lt;/a&gt; where you can test their model.&lt;/p&gt;

&lt;h2 id=&#34;deep-gold-https-hackernoon-com-deep-gold-using-convolution-networks-to-find-minerals-aafdb37355df-bzdqahgbh&#34;&gt;&lt;a href=&#34;https://hackernoon.com/deep-gold-using-convolution-networks-to-find-minerals-aafdb37355df#.bzdqahgbh&#34;&gt;Deep Gold&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Deep learning on images has been around for sometime right now and we have seen some really impressive results. Similarly for finding locations that may have minerals or oil, satellite images are used, they are judged by geologists, who give a conclusion. The author &lt;a href=&#34;https://hackernoon.com/deep-gold-using-convolution-networks-to-find-minerals-aafdb37355df#.bzdqahgbh&#34;&gt;here&lt;/a&gt; has developed a convolutional net that when trained, tells you the possible locations of a goldmine field. Though the results are not really impressive, but it has shown what more we can expect from DL in next few years. DL to find Oil is coming soon.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Good deep learning posts</title>
      <link>https://shubhamjain0594.github.io/post/good-deep-learning-blog-posts/</link>
      <pubDate>Mon, 12 Sep 2016 18:50:05 +0530</pubDate>
      
      <guid>https://shubhamjain0594.github.io/post/good-deep-learning-blog-posts/</guid>
      <description>

&lt;p&gt;I am an avid reader and spend a lot of time commuting between home and work. I use this time to read blogs, news and papers. In this article I present some cool blog posts that I found and a very short summary. I will add more links as time permits. I have divided blog posts based on the audience it caters to, beginners and intermediate. I believe experts would dive directly into reading papers and won&amp;rsquo;t spend much time reading blogs. Also, are some really good non-technical articles as deserts and some random posts relating to AI as side dishes.&lt;/p&gt;

&lt;h2 id=&#34;starters&#34;&gt;Starters&lt;/h2&gt;

&lt;h3 id=&#34;a-brief-overview-of-deep-learning-ilya-sutskever-http-yyue-blogspot-in-2015-01-a-brief-overview-of-deep-learning-html&#34;&gt;&lt;a href=&#34;http://yyue.blogspot.in/2015/01/a-brief-overview-of-deep-learning.html&#34;&gt;A brief overview of deep learning - Ilya Sutskever&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;This blog post by &lt;a href=&#34;http://www.cs.toronto.edu/~ilya/&#34;&gt;Ilya Sutskever&lt;/a&gt;, also a research director at &lt;a href=&#34;https://openai.com&#34;&gt;OpenAI&lt;/a&gt; is one of the must read posts for any one diving into deep learning for practical applications. It gives you an insight into why it works, some things you must keep in mind for practical purposes and if you love it, you can just dive into comments section for some cool conversation between &lt;a href=&#34;http://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html&#34;&gt;Bengio&lt;/a&gt; and Ilya.&lt;/p&gt;

&lt;h2 id=&#34;main-course&#34;&gt;Main Course&lt;/h2&gt;

&lt;h3 id=&#34;an-overview-of-gradient-descent-optimization-algorithms-http-sebastianruder-com-optimizing-gradient-descent&#34;&gt;&lt;a href=&#34;http://sebastianruder.com/optimizing-gradient-descent/&#34;&gt;An overview of gradient descent optimization algorithms&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;If you have just started deep learning and have run a model over MNIST, then this is a must read post. Last few years have seen number of optimization algorithms for learning weights of a neural net. From Gradient Descent to Adaboost, we are left with many choices. This post lists down all the optimization algorithms, some mathematics and intuition behind it and the default parameters you may like to play with. A very comprehensize survey, it is again a must read article if you are doing applied deep learning for something serious.&lt;/p&gt;

&lt;h2 id=&#34;desserts&#34;&gt;Desserts&lt;/h2&gt;

&lt;h3 id=&#34;hyperparameter-optimization-by-efficient-configuration-evaluation-http-www-argmin-net-2016-06-23-hyperband&#34;&gt;&lt;a href=&#34;http://www.argmin.net/2016/06/23/hyperband/&#34;&gt;Hyperparameter optimization by efficient configuration evaluation&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;One of the major challenges in deep learning is how you select the hyper-parameters for your training or for post processing in some cases. There are numerous techniques for hyper-parameter search, &lt;a href=&#34;http://www.jmlr.org/papers/volume13/bergstra12a/bergstra12a.pdf&#34;&gt;random-search optimization&lt;/a&gt; by Bergstra et.al&amp;rsquo;12 is one of the heavily used techniques. &lt;a href=&#34;https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf&#34;&gt;This&lt;/a&gt; paper by Bergstra, Bengio highlights some of the algorithms used. In this blog, author introduces a new algorithm known as Hyperband which uses random search algorithm and uses simple technique of divide and rule to optimize. The results by the optimization are promising and is a very simple algorithm to understand and implement. One can find the complete paper &lt;a href=&#34;https://people.eecs.berkeley.edu/~kjamieson/hyperband.html&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;side-dishes&#34;&gt;Side dishes&lt;/h2&gt;

&lt;h3 id=&#34;the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe-henry-lin-harvard-and-max-tegmark-mit-https-www-technologyreview-com-s-602344-the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe&#34;&gt;&lt;a href=&#34;https://www.technologyreview.com/s/602344/the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe/&#34;&gt;The extraordinary link between deep neural networks and the nature of the universe - Henry Lin (Harvard) and Max Tegmark (MIT) &lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&amp;ldquo;Why deep learning works?&amp;rdquo; - This is one of the most intriguing questions for all involved in deep learning. We try to convince ourselves giving various answers for the question, similarity with the eye structure, universal approximator, etc. Our friends from MIT and Harvard have come up with a much better, mathematical but still a bit vague explanation for the success of deep learning, by comparing the laws used to predict physical phenomenons and how we can derive complete physics using few rules and parameters, thus explaining the whole world around us. For similar reasons, all visual information can be explained/derived from small parameters. The blog gives a beautiful insight into this relation and for more mathematical treatment one can look into the &lt;a href=&#34;http://arxiv.org/abs/1608.08225&#34;&gt;paper&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;lists-to-refer&#34;&gt;Lists to refer&lt;/h2&gt;

&lt;h3 id=&#34;deep-learning-papers-reading-roadmap-https-github-com-songrotek-deep-learning-papers-reading-roadmap&#34;&gt;&lt;a href=&#34;https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap&#34;&gt;Deep Learning Papers Reading Roadmap&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;If you are starting into deep learning then this might be a great place to look at.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>